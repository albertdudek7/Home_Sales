# Home_Sales with PySpark SQL

Utilizing PySpark and Spark SQL on Google Colab, this project determined key metrics regarding home sales data.
Spark was utilized to create temporary views, partition the data and uncache a tempory table.

The questions below were answered: 

What is the average price for a four-bedroom house sold for each year? Round off your answer to two decimal places.

What is the average price of a home for each year it was built that has three bedrooms and three bathrooms? Round off your answer to two decimal places.

What is the average price of a home for each year that has three bedrooms, three bathrooms, two floors, and is greater than or equal to 2,000 square feet? Round off your answer to two decimal places.

What is the "view" rating for homes costing more than or equal to $350,000? Determine the run time for this query, and round off your answer to two decimal places.





![spark](https://github.com/albertdudek7/Home_Sales/assets/127783844/174c21f7-3bac-4777-b0a8-0b54851d39d8)
![spark2](https://github.com/albertdudek7/Home_Sales/assets/127783844/13686e97-ae6e-4b04-a1df-adfe3213e450)
![spark3](https://github.com/albertdudek7/Home_Sales/assets/127783844/a401b945-9c31-46ac-8245-f222d29c1f61)







